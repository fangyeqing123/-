// 1.文件切片 切成了100块
//   1.依次上传
//   2.100上传完毕后，通知后端合并/merge
//   3.如果传了20个之后，网断了
//   4.下次每个切片上传之前，问一下后端，我这个切片在不在
//     1. 后端告诉你 你已经上传过了 直接显示切片上传成功
//     2. 断点续传
//   5.如果整个文件都上传完毕了 也会问后端 文件如果存在 那就直接提示上传成功，秒传
// 判断文件存在与否通过文件的hash值，我们使用md5加密

// 1.判断文件的唯一性，你要计算md5，如果文件过大，计算hash就会卡顿
//     1.web-Worker
//         1.影分身一个小弟，web-workder 让他去干计算hash的值
//         2.计算量没有减小，但是主线程不卡顿
//     2.通过学习react源码，时间切片的概念
//         1.自己切片时间
//         2.游览器闲的时候，计算hash，游览器来任务了，计算hash终端，下次闲的时候，再计算
//         3.时间切片，time-slice,fiber核心都是这个玩意儿
//         4.requestIdleCallback 利用游览器的空闲时间
//           requestIdleCallback 第一个参数是传入一个回调 回调中可以获取到deadline这个参数 deadline.timeRemaining()>0 代表当前帧有空余时间
// 抽样hash 取文件切片首尾的全部和中间每个切片的首中尾各两个字节 布隆过滤器
// 缺点: 比如我修改了第二个切片中的第三个数据 会导致少量的误判
// 优点：是快
//       1.命中了偶尔误判
//       2.不命中 肯定不重复
//       3.抽样文件不上传，只是计算一个唯一标识，然后上传的还是真实的文件
//          1.为了提高秒传的判断效率
//          2.为了提高hsh的计算效率

// 优化
    // 1.自己实现一个兼容性高的requestIdleCallback
    // 2.并发+慢启动配合
    // 3.抽样hash+全量哈希+时间切片的配合
    // 4.大文件切片下载
    //     1.一样的切片逻辑，通过axios.head请求获取content-length
    //     2.使用http的Range这个header就可以切片下载了，其他逻辑和上传差不多
    // 5.小的体验优化
    //     1.比如离开页面的提醒 等等小tips
    // 6.慢启动的变化应该更平滑，比如使用三角函数，把变化率平滑的控制在0.5~1.5之间
    // 7.websocket推送进度
    // 8.文件碎片分机器存储
    // 9.文件碎片备份
    // 10.cdn